{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize the activation function\n",
    "\n",
    "Modification based on [Ref](https://medium.com/@chinesh4/custom-activation-function-in-tensorflow-for-deep-neural-networks-from-scratch-tutorial-b12e00652e24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customize activation    \n",
    "\n",
    "#work/python/keras-1\n",
    "\n",
    "#work/DNN/Comparison-activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Gaussin Radial Basis Function](https://en.wikipedia.org/wiki/Radial_basis_function) is defined as\n",
    "$$\n",
    "\\phi(x) = e^{-(\\epsilon r)^2}\n",
    "$$\n",
    "\n",
    "We found out that radial basis function works pretty good as an activation in a network, this will be demonstrated in the following tutorials. The raial basis function only makes a difference in an interval close to the center which is similar to the idea of \"on-and-off\" of an activation function.\n",
    "\n",
    "In a dimension 1 space, let us set activation to be $\\phi(x)=e^{-x^2}$. Since this is not in TensorFlow's list of activation functions https://www.tensorflow.org/api_docs/python/tf/keras/activations, we will use it for demonstration of customizing activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#define the activation function\n",
    "def rbf(x):\n",
    "    return tf.math.exp(-x**2)\n",
    "\n",
    "#######################################\n",
    "#define the derivative of the activation function\n",
    "def d_rbf(x):\n",
    "    return tf.gradients(rbf,x)\n",
    "\n",
    "#######################################\n",
    "#we couldn't use “d_rbf” as an activation function if we wanted to \n",
    "#because tensorflow doesn't know how to calculate the gradients of that function.\n",
    "def rbf_grad(op, grad):\n",
    "    x = op.inputs[0]\n",
    "    n_gr = d_rbf(x)    #defining the gradient.\n",
    "    return grad * n_gr\n",
    "\n",
    "def py_func(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "    # Need to generate a unique name to avoid duplicates:\n",
    "    rnd_name = 'PyFuncGrad' + str(np.random.randint(0, 1E+2))\n",
    "    tf.RegisterGradient(rnd_name)(grad)\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": rnd_name, \"PyFuncStateless\": rnd_name}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)\n",
    "    \n",
    "def tf_rbf(x,name=None):\n",
    "    with tf.name_scope(name, \"rbf\", [x]) as name:\n",
    "        y = py_func(rbf,   #forward pass function\n",
    "                    [x],\n",
    "                    [tf.float32],\n",
    "                    name=name,\n",
    "                    grad= rbf_grad) #the function that overrides gradient\n",
    "        y[0].set_shape(x.get_shape())     #when using with the code, it is used to specify the rank of the input.\n",
    "    return y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training data\n",
    "np.random.seed(1)\n",
    "x_train = np.linspace(-40,40,20)\n",
    "y_train = 0.3*x_train**2 + np.random.normal(0, 1, len(x_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.6122294e-03,  1.6906145e-03, -2.2995217e+00]], dtype=float32),\n",
       " array([-4.2092835e-04,  2.8977118e-04,  4.8410983e+00], dtype=float32),\n",
       " array([[  57.36145 ],\n",
       "        [  59.288876],\n",
       "        [-115.397705]], dtype=float32),\n",
       " array([55.409958], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rbf = tf.keras.Sequential()\n",
    "model_rbf.add(tf.keras.layers.Dense(3,activation=rbf))     #no need to put quote around rbf\n",
    "model_rbf.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model_rbf.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))\n",
    "model_rbf.fit(x_train,y_train, epochs=1000, verbose=0)\n",
    "\n",
    "# model.summary()\n",
    "model_rbf.get_weights()   #test if model is trained successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutomize the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(3,activation=rbf))     #no need to put quote around rbf\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize loss\n",
    "def custom_loss(ytrue,ypred):\n",
    "    val = tf.math.reduce_mean(tf.math.square((ytrue-ypred)/10))\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.8343139e-05, -1.8820183e-01,  5.0299735e-05]], dtype=float32),\n",
       " array([1.9036455e-05, 5.2888556e-03, 2.9459905e-05], dtype=float32),\n",
       " array([[ 5.030023 ],\n",
       "        [-4.4802723],\n",
       "        [ 4.8218493]], dtype=float32),\n",
       " array([3.9862227], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=custom_loss,optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "model.fit(x_train,y_train,epochs=100,verbose=0)\n",
    "\n",
    "model.get_weights()    #test if model is trained successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
