{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow** is a free and open-source software library for machine learning.\n",
    "\n",
    "**Keras** is a deep learning API written in Python, running on top of the machine learning platform TensorFlow.\n",
    "\n",
    "## History between Keras and TensorFlow:\n",
    "\n",
    "- Keras was first developed by Francois Chollet for his own reserach in March 27th, 2015. Back then, TensorFlow hasn't been developed. There weren't too many deep learning libraries available - the popular ones included Torch, Theano, and Caffe. \n",
    "- In order to train the neural networks, Keras required a **backend** (computational engine). Keras's default backend was Theano until v1.1.0. At the same time, Google released TensorFlow. Keras started supporting it as a backend, and became the default starting from the release of Keras v1.1.0.\n",
    "     - Keras started making TensorFlow default due to its popularity; and TensorFlow users were also becoming increasingly drawn to the simplicity of the high-level Keras API.\n",
    "- Google announced TensorFlow 2.0 in June 2019, they declared that Keras is now the official high-level API of TensorFlow.\n",
    "\n",
    "[Link](https://www.pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras and tf.keras\n",
    "\n",
    "- tf.keras submodule was introduced in TensorFlow v1.10.0, integrating Keras directly within TensorFlow package itself.\n",
    "- Release of Keras 2.3.0: \n",
    "     - It is the first release of Keras that brings the Keras package in sync with tf.keras\n",
    "     - It is the final release of Keras that will support multiple backends \n",
    "     - The keras package will only support bug fixes. Developers should start using tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras == keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.Sequential == keras.models.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.models.Model == tf.keras.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eager Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no session\n",
    "\n",
    "no initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=Up9CvRLIIIw\n",
    "\n",
    "@tf.function\n",
    "\n",
    "a.assign\n",
    "a.assign_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager execution is a powerful execution environment that evaluates operations immediately. It does not build graphs, and the operations return actual values instead of computational graphs to run later. With Eager execution, TensorFlow calculates the values of tensors as they occur in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Tensorflow 2.0, eager execution is enabled by default.\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, [[4.]]\n"
     ]
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x,x)\n",
    "print(\"hello, {}\".format(m))     #Return results immediately "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow1.x, the above code will return:\n",
    "\n",
    "      hello, Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager execution\n",
    "\n",
    "<font color= red>Easy-to-build\\&test</font>\n",
    "\n",
    "Eager execution is easy to implement, and simplify the model building experience. Advantages of eager execution:\n",
    "\n",
    "- **An intuitive interface** with natural Python code and data structures;\n",
    "- **Easier debugging** with calling operations directly to inspect and test models;\n",
    "- **Natural control flow** with Python, instead of graph control flow; and\n",
    "- Support for **GPU & TPU acceleration**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph execution\n",
    "\n",
    "<font color= red>Efficient and fast</font>\n",
    "\n",
    "Eager execution is slower than graph execution since eager execution runs all operations one-by-one in Python, it cannot take advantage of potential acceleration opportunities.\n",
    "\n",
    "Graphs are easy-to-optimize, simplify arithmetic operations. In graph execution, evaluation of all the operations happens only after we've called our program entirely. So, graph execution is\n",
    "- **Very Fast**\n",
    "- **Very Flexible**\n",
    "- **Runs in parallel**, even in sub-operation level;\n",
    "- **Very efficient**, on multiple devices\n",
    "- with **GPU & TPU acceleration** capability\n",
    "\n",
    "Graph execution is ideal for large model training. For small model training, beginners, eager execution is better suited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why TensorFlow adopted Eager Execution?\n",
    "\n",
    "- Before version 2.0, TensorFlow prioritized graph execution because it was fast, effiicent, and flexible. But it is difficult to implement.\n",
    "- PyTorch adopted a different approach and prioritized dynamic computation graphs, which is a similar concept to eager execution. Although they are not that efficient, it is intuitive and easy to implement. Then PyTorch became attractive for the newcommers.\n",
    "- TensorFlow felt threatened, so the TensorFlow team adopted eager execution as the default execution method, and graph execution is optional.\n",
    "\n",
    "In TensorFlow 2.0, you can decorate a Python function using tf.function() to run it as a single graph object. With this new method, you can easily build models and gain all the graph execution benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2],[3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "b = tf.add(a,1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]]\n"
     ]
    }
   ],
   "source": [
    "c = np.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "- variables\n",
    "- constant\n",
    "- Placeholder\n",
    "- SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scalar\n",
    "string = tf.Variable(\"this is a string\", tf.string) \n",
    "number = tf.Variable(324, tf.int16)\n",
    "floating = tf.Variable(3.567, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=324>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable([[0.3,0.5],[1,0.2]],dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1_tensor = tf.Variable([\"Test\"], tf.string) \n",
    "rank2_tensor = tf.Variable([[\"test\", \"ok\"], [\"test\", \"yes\"]], tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(rank1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank2_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(1, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]], shape=(2, 3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.ones([1, 2, 3])  #tf.zeros\n",
    "print(tensor1)\n",
    "# y.numpy()     #no numpy()\n",
    "tensor2 = tf.reshape(tensor1,[2,3,1])\n",
    "print(tensor2)\n",
    "tensor3 = tf.reshape(tensor2,[3,-1])\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work/DNN/scratch\n",
    "\n",
    "#work/DNN/ODE-tf/tf2 vs tf1 (eg from stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4.]\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    x = tf.constant([1., 2.])\n",
    "    y = x**2\n",
    "    tf.compat.v1.global_variables_initializer().run()\n",
    "    print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 4.]\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    x = tf.constant([1., 2.])\n",
    "    y = x**2\n",
    "    print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [4.]]\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "x = tf.compat.v1.placeholder(tf.float64,[None,1])\n",
    "y = x**2\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    a = np.array([[1],[2]])   #cannot be tf.constant\n",
    "    c = sess.run(y,feed_dict={x:a})    #print(c) not print(y)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'PartitionedCall:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'PartitionedCall:1' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def example():\n",
    "    a = tf.constant(0.)\n",
    "    b = 2 * a **2\n",
    "    return tf.gradients(a + b, [a, b], stop_gradients=[a, b])\n",
    "\n",
    "example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.gradients\n",
    "\n",
    "x = tf.Variable(2.0)\n",
    "y = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    x_sq = x * x\n",
    "    with t.stop_recording():\n",
    "        y_sq = y * y\n",
    "    z = x_sq + y_sq\n",
    "\n",
    "grad = tf.gradient(z, {'x': x, 'y': y})\n",
    "\n",
    "print('dz/dx:', grad['x'])  # 2*x => 4\n",
    "print('dz/dy:', grad['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple tapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work/python/keras-1\n",
    "\n",
    "x0 = tf.constant(0.0)\n",
    "x1 = tf.constant(0.0)\n",
    "\n",
    "with tf.GradientTape() as tape0, tf.GradientTape() as tape1:\n",
    "    tape0.watch(x0)\n",
    "    tape1.watch(x1)\n",
    "\n",
    "    y0 = tf.math.sin(x0)\n",
    "    y1 = tf.nn.sigmoid(x1)\n",
    "\n",
    "    y = y0 + y1\n",
    "\n",
    "    ys = tf.reduce_sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tape0.gradient(ys, x0).numpy())  # cos(x) => 1.0\n",
    "\n",
    "print(tape1.gradient(ys, x1).numpy())   # sigmoid(x1)*(1-sigmoid(x1)) => 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "higher-order gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work/python/keras-1\n",
    "\n",
    "x = tf.Variable(1.0)  # Create a Tensorflow variable initialized to 1.0\n",
    "\n",
    "with tf.GradientTape() as t2:\n",
    "    with tf.GradientTape() as t1:\n",
    "        y = x * x * x\n",
    "\n",
    "    # Compute the gradient inside the outer `t2` context manager\n",
    "    # which means the gradient computation is differentiable as well.\n",
    "    dy_dx = t1.gradient(y, x)\n",
    "d2y_dx2 = t2.gradient(dy_dx, x)\n",
    "\n",
    "print('dy_dx:', dy_dx.numpy())  # 3 * x**2 => 3.0\n",
    "print('d2y_dx2:', d2y_dx2.numpy())  # 6 * x => 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work/python/keras-1\n",
    "\n",
    "# x has a shape of (2, 3) (two rows and three columns):\n",
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "print(x.numpy())\n",
    "\n",
    "# sum all the elements\n",
    "# 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
    "print(tf.reduce_sum(x).numpy())\n",
    "\n",
    "# reduce along the first dimension\n",
    "# the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
    "print(tf.reduce_sum(x, 0).numpy())\n",
    "\n",
    "# reduce along the second dimension\n",
    "# the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
    "print(tf.reduce_sum(x, 1).numpy())\n",
    "\n",
    "# keep the original dimensions\n",
    "print(tf.reduce_sum(x, 1, keepdims=True).numpy())\n",
    "\n",
    "\n",
    "# reduce along both dimensions\n",
    "# the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
    "# or, equivalently, reduce along rows, then reduce the resultant array\n",
    "# [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
    "# 2 + 2 + 2 = 6\n",
    "print(tf.reduce_sum(x, [0, 1]).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.dynamic_stitch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.slice    #work/DNN/scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.get_variable     #work/DNN/scratch\n",
    "\n",
    "var2 = tf.compat.v1.get_variable(initializer=tf.constant_initializer(3.), dtype=tf.float64, name=\"var1\", shape=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.square(2)    #work/DNN/scratch\n",
    "\n",
    "def mysquare(x):\n",
    "    return tf.math.square(x)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    xx = tf.constant([1., 2.])\n",
    "    yy = mysquare(xx)\n",
    "    tf.compat.v1.global_variables_initializer().run()\n",
    "\n",
    "    print(xx.eval(), yy.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
